{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gs9Bnl6Nvkz7","colab_type":"code","colab":{}},"source":["def mount_drive():\n","  from google.colab import drive\n","  import os\n","  drive.mount('gdrive')\n","  os.chdir('gdrive/My Drive/movie plot')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrQvEp3dvty9","colab_type":"code","colab":{}},"source":["def get_embedding_dictionary():\n","  import numpy as np\n","  return np.load(\"embedding dictionary.npy\",allow_pickle=True).item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eS2uy2Z6zsun","colab_type":"code","colab":{}},"source":["def get_tokenizer(corpus,num_words):\n","  from tensorflow.keras.preprocessing.text import Tokenizer\n","  tokenizer=Tokenizer(num_words=num_words, oov_token='<OOV>')\n","  tokenizer.fit_on_texts(train_plots)\n","  return tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XbDAUhHk0H_z","colab_type":"code","colab":{}},"source":["def get_train():\n","  import pandas as pd\n","  train=pd.read_csv(\"train.csv\")\n","  train_plots=train[\"plots\"].to_numpy()\n","  train_labels=train[\"labels\"].to_numpy()\n","  return train_plots,train_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKxZYJBSFDE1","colab_type":"code","colab":{}},"source":["def get_test():\n","  import pandas as pd\n","  test=pd.read_csv(\"test.csv\")\n","  test_plots=test[\"plots\"].to_numpy()\n","  test_labels=test[\"labels\"].to_numpy()\n","  return test_plots,test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2bbj8Vw0bPF","colab_type":"code","colab":{}},"source":["def get_padding_sentence(corpus,tokenizer,maxlen):\n","  from tensorflow.keras.preprocessing.sequence import pad_sequences\n","  seq=tokenizer.texts_to_sequences(corpus)\n","  seq = pad_sequences(seq, padding='post',maxlen=maxlen)\n","  return seq"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAjZba3Owp51","colab_type":"code","colab":{}},"source":["def get_sentence_embedding(sentence_batch,tokenizer):\n","  no_embedding=0\n","  with_embedding=0\n","  import numpy as np\n","  word2embedding=get_embedding_dictionary()\n","  index2word = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n","  bound = np.sqrt(6.0) / np.sqrt(10000) \n","  embeddings=[]\n","  for sentence in sentence_batch:\n","    vectors=[]\n","    for index in sentence:\n","      if index!=0:\n","        word=index2word[index]\n","      else:\n","        word=None\n","      embedding=None\n","      try:\n","        embedding=word2embedding[word]\n","        with_embedding+=1\n","      except:\n","        no_embedding+=1\n","        pass\n","      if embedding is not None:\n","        vectors.append(embedding)\n","      else:\n","        vectors.append(np.random.uniform(-bound, bound, 300))\n","    embeddings.append(vectors)\n","  print(\"%d words have embedding, while\"%with_embedding,\"%d words do not\"%no_embedding)\n","  return np.array(embeddings)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCgUIdR1_R5f","colab_type":"code","colab":{}},"source":["def get_sentence_embedding_(sentence_batch,tokenizer):\n","  no_embedding=0\n","  with_embedding=0\n","  import numpy as npimport sys\n","sys.path.append('/content/gdrive/mypythondirectory')\n","  #word2embedding=get_embedding_dictionary()\n","  from gensim import models\n","\n","  model = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True) \n","  index2word = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n","  bound = np.sqrt(6.0) / np.sqrt(10000) \n","  embeddings=[]\n","  for sentence in sentence_batch:\n","    vectors=[]\n","    for index in sentence:\n","      if index!=0:\n","        word=index2word[index]\n","      else:\n","        word=None\n","      embedding=None\n","      try:\n","        embedding=model.word_vec(word)\n","        with_embedding+=1\n","      except:\n","        no_embedding+=1\n","        pass\n","      if embedding is not None:\n","        vectors.append(embedding)\n","      else:\n","        vectors.append(np.random.uniform(-bound, bound, 300))\n","    embeddings.append(vectors)\n","  print(\"%d words have embedding, while\"%with_embedding,\"%d words do not\"%no_embedding)\n","  return np.array(embeddings)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTNxnOry0xt7","colab_type":"code","colab":{}},"source":["mount_drive()\n","train_plots,train_labels=get_train()\n","tokenizer=get_tokenizer(train_plots,20000)\n","#train_plots=get_padding_sentence(train_plots,tokenizer,100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JL1vjNGy1bXh","colab_type":"code","colab":{}},"source":["#e=get_sentence_embedding_(train_plots,tokenizer)\n","#print(e.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OU8ZIsum3hNp","colab_type":"code","colab":{}},"source":["#import numpy as np\n","#np.save(\"train plots with embedding(first 100 grams).npy\",e)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNadpTZnEiiE","colab_type":"code","colab":{}},"source":["#ee=np.load(\"train plots with embedding(first 100 grams).npy\")\n","#print(ee.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3136bpOSE46V","colab_type":"code","colab":{}},"source":["test_plots,test_labels=get_test()\n","test_plots=get_padding_sentence(test_plots,tokenizer,100)\n","e=get_sentence_embedding_(test_plots,tokenizer)\n","print(e.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdnl1TJeGhmW","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.save(\"test plots with embedding(first 100 grams).npy\",e)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wqSJ1qwItls","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}